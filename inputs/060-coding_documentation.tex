\hypertarget{pyinfomap}{\section{Infomap implementation in
Python}\label{pyinfomap}}

\protect\hyperlink{pyinfomap}{}

The code I am submitting is my work on a Python implementation of
Infomap: \url{https://github.com/h1-the-swan/pyinfomap}

As far as I know, there does not yet exist a pure Python implementation
of Infomap, the algorithm to detect communities in network data by
minimizing the map equation. The Infomap software, available at
\url{http://www.mapequation.org/code.html}, is written in C++, although
it has extensions in other languages including Python. A Python
repository was created by Daniel Halperin in
2013---\url{https://github.com/uwescience/pyinfomap}. This code, deemed
version 1 by Dr.~Halperin, is capable of calculating the map equation
for a given network and a given two-level clustering of its
nodes.\footnote{By ``two-level clustering'', I mean a non-hierarchical,
  non-overlapping partitioning of each node into exactly one of any
  number of clusters.} My code is a fork of this repository: I coded the
algorithm starting with this code that can calculate the function to
optimize.

The map equation is (see section
\protect\hyperlink{the-dynamical-perspective}{``The dynamical
perspective''} for background):
\[L(\mathsf{M}) = q_{\curvearrowright} H(\mathcal{Q}) + \sum_{i=1}^{m}{p_{\circlearrowright}^{i} H(\mathcal{P}^i)}\]
where \(\mathsf{M}\) is the module partitioning; the left term is the
average length of codewords (entropy) in the index codebook weighted by
the rate of use of the index codebook \(q_{\curvearrowright}\); and the
right term is the average length of codewords in module codebook \(i\)
weighted by the rate of use of this module \(p_{\circlearrowright}\).
Using \(q_{\curvearrowright} = \sum_{i=1}^{m}{q_{i\curvearrowright}}\);
\(p_{\circlearrowright}^{i} = \sum_{\alpha \in i}{p_{\alpha}} + q_{i\curvearrowright}\)
where \(\alpha \in i\) means every node in module \(i\) (the
\(q_{i\curvearrowright}\) is added as the probability that the random
walker exits the module and the exit codeword is used); and the
definition of entropy\footnote{For a random variable \(X\) that can have
  \(n\) states with probability \(p_i\), the entropy is
  \(H(X) = -\sum_{i=1}^{n}{p_i\log{p_i}}\).}, the map equation can be
expanded to: \[
\begin{aligned}
L(\mathsf{M}) = &\left(\sum_{i=1}^{m}{q_{\curvearrowright}}\right) 
                                        \log \left(\sum_{i=1}^{m}{q_{\curvearrowright}}\right)
                                        - 2 \sum_{i=1}^{m}{q_{\curvearrowright}} \log (q_{\curvearrowright)} \\
                                &- \sum_{\alpha=1}^{n}{p_{\alpha} \log(p_\alpha)}
                                        + \sum_{i=1}^{m}{\left(q_{\curvearrowright} + \sum_{\alpha \in i}{p_{\alpha}}\right) \log \left(q_{\curvearrowright} + \sum_{\alpha \in i}{p_{\alpha}}\right)}
\end{aligned}
\]

The node visit probability \(p_{\alpha}\) is related to the dynamics
being modeled. Dr.~Halperin's code uses PageRank with teleportation
probability \(\tau = 0.15\). This is modeling a random walker on the
network that has a 15\% chance, on every step, of teleporting to a
random node instead of following a link as normal. The exit probability
\(q_{i\curvearrowright}\) is then calculated as
\autocite{rosvall_map_2010}:
\[q_{i\curvearrowright} = \tau \frac{n-n_i}{n} \sum_{\alpha \in i}{p_{\alpha}} + (1-\tau) \sum_{\alpha \in i}{\sum_{\beta \notin i}{p_{\alpha}w_{\alpha \beta}}}\]
where \(n_i\) is the number of nodes in module \(i\), and
\(w_{\alpha \beta}\) is the normalized weight of the link from
\(\alpha\) to \(\beta\) (if \(\alpha\) is a dangling node, this weight
is replaced by \(1-n_i/n\)).
